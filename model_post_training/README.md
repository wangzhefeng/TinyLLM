# Post-training

* Supervised finetuning(SFT)
    - Instruction finetuning
* Reinforcement Learning with Hunman Feedback(RLHF)
* Direct Preference Optimization(DPO)
* Online
    - 现有数据集上
* Offline
    - 奖励模型选择偏好响应实时应用于优化步骤（即在训练期间）
* Knowledge distillation
* Synthetic data


## TODO

* SFT Only
* SFT + RLHF
* SFT + DPO
